{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IP_Address_Test_GoogleBooks_API.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXWPstI+Bj/90Tof3sLzF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zernach/BetterReads-DS/blob/master/IP_Address_Test_GoogleBooks_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4Opxrf2x-b3",
        "colab_type": "text"
      },
      "source": [
        "# IP Address Proxy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "025oZQCDll1O",
        "colab_type": "code",
        "outputId": "d96b9916-c1f9-4200-98ef-69990f72158b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!curl ipecho.net/plain"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35.223.189.101"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCTdkEa54rv9",
        "colab_type": "code",
        "outputId": "970b6cf8-faba-41ce-90b0-ea9c2c676685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "chmod 777 /tmp\n",
        "mkdir data\n",
        "apt-get update --allow-unauthenticated \n",
        "apt-get update -y --fix-missing \n",
        "pip install selenium\n",
        "apt-get install chromium-chromedriver -y --fix-missing\n",
        "pip install joblib\n",
        "apt-get update --fix-missing"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [91.7 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [8,505 B]\n",
            "Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [48.3 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [843 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [903 kB]\n",
            "Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.4 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,376 kB]\n",
            "Get:21 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,813 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,205 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [12.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [66.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [8,286 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [7,671 B]\n",
            "Get:27 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [875 kB]\n",
            "Fetched 7,589 kB in 4s (2,144 kB/s)\n",
            "Reading package lists...\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists...\n",
            "Collecting selenium\n",
            "  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 108 not upgraded.\n",
            "Need to get 74.4 MB of archives.\n",
            "After this operation, 264 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 80.0.3987.163-0ubuntu0.18.04.1 [1,095 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 80.0.3987.163-0ubuntu0.18.04.1 [66.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 80.0.3987.163-0ubuntu0.18.04.1 [3,160 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 80.0.3987.163-0ubuntu0.18.04.1 [4,045 kB]\n",
            "Fetched 74.4 MB in 3s (21.4 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 144568 files and directories currently installed.)\r\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_80.0.3987.163-0ubuntu0.18.04.1_amd64.deb ...\r\n",
            "Unpacking chromium-codecs-ffmpeg-extra (80.0.3987.163-0ubuntu0.18.04.1) ...\r\n",
            "Selecting previously unselected package chromium-browser.\r\n",
            "Preparing to unpack .../chromium-browser_80.0.3987.163-0ubuntu0.18.04.1_amd64.deb ...\r\n",
            "Unpacking chromium-browser (80.0.3987.163-0ubuntu0.18.04.1) ...\r\n",
            "Selecting previously unselected package chromium-browser-l10n.\r\n",
            "Preparing to unpack .../chromium-browser-l10n_80.0.3987.163-0ubuntu0.18.04.1_all.deb ...\r\n",
            "Unpacking chromium-browser-l10n (80.0.3987.163-0ubuntu0.18.04.1) ...\r\n",
            "Selecting previously unselected package chromium-chromedriver.\r\n",
            "Preparing to unpack .../chromium-chromedriver_80.0.3987.163-0ubuntu0.18.04.1_amd64.deb ...\r\n",
            "Unpacking chromium-chromedriver (80.0.3987.163-0ubuntu0.18.04.1) ...\r\n",
            "Setting up chromium-codecs-ffmpeg-extra (80.0.3987.163-0ubuntu0.18.04.1) ...\r\n",
            "Setting up chromium-browser (80.0.3987.163-0ubuntu0.18.04.1) ...\r\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\r\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\r\n",
            "Setting up chromium-chromedriver (80.0.3987.163-0ubuntu0.18.04.1) ...\r\n",
            "Setting up chromium-browser-l10n (80.0.3987.163-0ubuntu0.18.04.1) ...\r\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\r\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\r\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\r\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.14.1)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Reading package lists...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNn4sft85Ie1",
        "colab_type": "code",
        "outputId": "03940180-9f56-4338-c60e-f82e5c546ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "URL = 'https://api.ipify.org?format=json'\n",
        "req = requests.get(URL) # .json()\n",
        "soup = BeautifulSoup(req.text, \"lxml\")\n",
        "ip = soup.find('p').text\n",
        "print('Your IP ', ip)\n",
        "\n",
        "# Your IP  {\"ip\":\"35.197.23.94\"} # Note: This will be different on your VM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your IP  {\"ip\":\"35.223.189.101\"}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWG0StPp5Ulg",
        "colab_type": "code",
        "outputId": "c06f3873-8ddb-4cd2-c6e9-35d34169dfcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
        "URL = 'https://api.ipify.org?format=json'\n",
        "proxy = {'https': '200.255.122.174:8080'}\n",
        "req = requests.get(URL, proxies = proxy, headers = headers) # .json()\n",
        "soup = BeautifulSoup(req.text, \"lxml\")\n",
        "ip = soup.find('p').text\n",
        "print('IP from scrape w/proxy ', ip)\n",
        "\n",
        "# Output\n",
        "# IP from scrape w/proxy  {\"ip\":\"200.255.122.174\"} # Tests proxy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ProxyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_new_proxy_conn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proxy_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x7ff8d19d8390>: Failed to establish a new connection: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.ipify.org', port=443): Max retries exceeded with url: /?format=json (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7ff8d19d8390>: Failed to establish a new connection: [Errno 110] Connection timed out',)))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-38f3aaef6733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://api.ipify.org?format=json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'https'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'200.255.122.174:8080'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# .json()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ProxyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProxyError\u001b[0m: HTTPSConnectionPool(host='api.ipify.org', port=443): Max retries exceeded with url: /?format=json (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7ff8d19d8390>: Failed to establish a new connection: [Errno 110] Connection timed out',)))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmU9lI0Y0TPi",
        "colab_type": "code",
        "outputId": "1b3d45c5-69eb-4d65-833d-6fe3f176adbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "from lxml.html import fromstring\n",
        "import requests\n",
        "from itertools import cycle\n",
        "import traceback\n",
        "\n",
        "def get_proxies():\n",
        "    url = 'https://free-proxy-list.net/'\n",
        "    response = requests.get(url)\n",
        "    parser = fromstring(response.text)\n",
        "    proxies = set()\n",
        "    for i in parser.xpath('//tbody/tr')[:10]:\n",
        "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
        "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
        "            proxies.add(proxy)\n",
        "    return proxies\n",
        "\n",
        "\n",
        "#If you are copy pasting proxy ips, put in the list below\n",
        "#proxies = ['121.129.127.209:80', '124.41.215.238:45169', '185.93.3.123:8080', '194.182.64.67:3128', '106.0.38.174:8080', '163.172.175.210:3128', '13.92.196.150:8080']\n",
        "proxies = get_proxies()\n",
        "proxy_pool = cycle(proxies)\n",
        "\n",
        "url = 'https://httpbin.org/ip'\n",
        "for i in range(1,11):\n",
        "    #Get a proxy from the pool\n",
        "    proxy = next(proxy_pool)\n",
        "    print(\"Request #%d\"%i)\n",
        "    try:\n",
        "        response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy})\n",
        "        print(response.json())\n",
        "    except:\n",
        "        #Most free proxies will often get connection errors. You will have retry the entire request using another proxy to work. \n",
        "        #We will just skip retries as its beyond the scope of this tutorial and we are only downloading a single url \n",
        "        print(\"Skipping. Connnection error\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Request #1\n",
            "Skipping. Connnection error\n",
            "Request #2\n",
            "Skipping. Connnection error\n",
            "Request #3\n",
            "Skipping. Connnection error\n",
            "Request #4\n",
            "Skipping. Connnection error\n",
            "Request #5\n",
            "Skipping. Connnection error\n",
            "Request #6\n",
            "Skipping. Connnection error\n",
            "Request #7\n",
            "{'origin': '81.217.151.218'}\n",
            "Request #8\n",
            "{'origin': '182.23.81.82'}\n",
            "Request #9\n",
            "Skipping. Connnection error\n",
            "Request #10\n",
            "{'origin': '182.23.81.82'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykp0x9CE1dxK",
        "colab_type": "code",
        "outputId": "7143fa6b-7319-410a-ec72-9f2be11b620c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "pip install scrapy-rotating-proxies"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scrapy-rotating-proxies\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/70/6336f2e74bdb2f617ff0cf5c5d80c7e94a991e3e0af027441b3b25006d9c/scrapy_rotating_proxies-0.6.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from scrapy-rotating-proxies) (1.12.0)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from scrapy-rotating-proxies) (19.3.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from scrapy-rotating-proxies) (3.6.6)\n",
            "Installing collected packages: scrapy-rotating-proxies\n",
            "Successfully installed scrapy-rotating-proxies-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzGTouO6yA5y",
        "colab_type": "text"
      },
      "source": [
        "# Code for GoogleBooks API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91DumSPJk_o5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Statements\n",
        "import requests\n",
        "import json\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import urllib\n",
        "#from secrets import GOOGLE_KEY\n",
        "\n",
        "#publishers = pd.read_csv(\"https://github.com/Lambda-School-Labs/betterreads-ds/blob/New_Data/notebooks/publishers.csv\")\n",
        "publishers = pd.read_csv(\"https://ryan.zernach.com/wp-content/uploads/2020/04/publishers.csv\")\n",
        "publishers['publisher'] = publishers['publisher'].apply(str)\n",
        "publishers['publishers'] = publishers['publisher'].apply(urllib.parse.quote)\n",
        "publishers_list = list(publishers['publishers'])\n",
        "\n",
        "publishers_list_test = publishers_list[1100:1200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wljFq2s7l2WG",
        "colab_type": "code",
        "outputId": "cb1fd1c2-74dd-48dc-adaa-bc0e551d89b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "cols = ['id', 'title', 'authors', 'publisher', 'publishedDate', 'description',\n",
        "        'isbn', 'pageCount', 'categories', 'thumbnail', 'smallThumbnail',\n",
        "        'language', 'webReaderLink', 'textSnippet', 'isEbook', 'averageRating',\n",
        "        'maturityRating', 'ratingsCount', 'subtitle']\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for publisher in publishers_list_test:\n",
        "\n",
        "        response = requests.get('https://www.googleapis.com/books/v1/volumes?q=inpublisher' + publisher + '&maxResults=' + '40')\n",
        "        data = json.loads(response.text)\n",
        "\n",
        "        try:\n",
        "\n",
        "          if data['totalItems'] == 0:\n",
        "            pass\n",
        "          else:\n",
        "\n",
        "            # Pagination Loop\n",
        "            # Insert code for loop\n",
        "\n",
        "            if data['totalItems'] >= 40:\n",
        "              end_of_loop = 40\n",
        "            else:\n",
        "              end_of_loop = data['totalItems']\n",
        "\n",
        "              for item in range(0, end_of_loop):\n",
        "\n",
        "                try:\n",
        "                  book_id = data['items'][item][cols[0]]\n",
        "                except Exception:\n",
        "                  book_id = math.nan\n",
        "\n",
        "                try:\n",
        "                  title = data['items'][item]['volumeInfo'][cols[1]]\n",
        "                except Exception:\n",
        "                  title = math.nan\n",
        "\n",
        "                try:\n",
        "                  authors = data['items'][item]['volumeInfo'][cols[2]][0]\n",
        "                except Exception:\n",
        "                  authors = math.nan\n",
        "\n",
        "                try:\n",
        "                  publisher = data['items'][item]['volumeInfo'][cols[3]]\n",
        "                except Exception:\n",
        "                  publisher = math.nan\n",
        "\n",
        "                try:\n",
        "                  publishedDate = data['items'][item]['volumeInfo'][cols[4]]\n",
        "                except Exception:\n",
        "                  publishedDate = math.nan\n",
        "              \n",
        "                try:\n",
        "                  description = data['items'][item]['volumeInfo'][cols[5]]\n",
        "                except Exception:\n",
        "                  description = math.nan\n",
        "              \n",
        "                try:\n",
        "                  isbn = data['items'][item]['volumeInfo']['industryIdentifiers'][1]['identifier']\n",
        "                except Exception:\n",
        "                  isbn = math.nan\n",
        "\n",
        "                try:\n",
        "                  pageCount = data['items'][item]['volumeInfo'][cols[7]]\n",
        "                except Exception:\n",
        "                  pageCount = math.nan\n",
        "\n",
        "                try:\n",
        "                  categories = data['items'][item]['volumeInfo'][cols[8]][0]\n",
        "                except Exception:\n",
        "                  categories = math.nan\n",
        "\n",
        "                try:\n",
        "                  thumbnail = data['items'][item]['volumeInfo']['imageLinks'][cols[9]]\n",
        "                except Exception:\n",
        "                  thumbnail = math.nan\n",
        "\n",
        "                try:\n",
        "                  smallThumbnail = data['items'][item]['volumeInfo']['imageLinks'][cols[10]]\n",
        "                except Exception:\n",
        "                  smallThumbnail = math.nan\n",
        "\n",
        "                try:\n",
        "                  language = data['items'][item]['volumeInfo'][cols[11]]\n",
        "                except Exception:\n",
        "                  language = math.nan\n",
        "\n",
        "                try:\n",
        "                  webReaderLink = data['items'][item]['accessInfo'][cols[12]]\n",
        "                except Exception:\n",
        "                  webReaderLink = math.nan\n",
        "\n",
        "                try:\n",
        "                  textSnippet = data['items'][item][cols[13]]\n",
        "                except Exception:\n",
        "                  textSnippet = math.nan\n",
        "\n",
        "                try:\n",
        "                  isEbook = data['items'][item]['saleInfo'][cols[14]]\n",
        "                except Exception:\n",
        "                  isEbook = math.nan\n",
        "\n",
        "                try:\n",
        "                  averageRating = data['items'][item]['volumeInfo'][cols[15]]\n",
        "                except Exception:\n",
        "                  averageRating = math.nan\n",
        "\n",
        "                try:\n",
        "                  maturityRating = data['items'][item]['volumeInfo'][cols[16]]\n",
        "                except Exception:\n",
        "                  maturityRating = math.nan\n",
        "\n",
        "                try:\n",
        "                  ratingsCount = data['items'][item]['volumeInfo'][cols[17]]\n",
        "                except Exception:\n",
        "                  ratingsCount = math.nan\n",
        "\n",
        "                try:\n",
        "                  subtitle = data['items'][item]['volumeInfo'][cols[18]]\n",
        "                except Exception:\n",
        "                  subtitle = math.nan\n",
        "\n",
        "                book_data = pd.DataFrame({cols[0]: book_id,\n",
        "                                        cols[1]: title,\n",
        "                                        cols[2]: authors,\n",
        "                                        cols[3]: publisher,\n",
        "                                        cols[4]: publishedDate,\n",
        "                                        cols[5]: description,\n",
        "                                        cols[6]: isbn,\n",
        "                                        cols[7]: pageCount,\n",
        "                                        cols[8]: categories,\n",
        "                                        cols[9]: thumbnail,\n",
        "                                        cols[10]: smallThumbnail,\n",
        "                                        cols[11]: language,\n",
        "                                        cols[12]: webReaderLink,\n",
        "                                        cols[13]: textSnippet,\n",
        "                                        cols[14]: isEbook,\n",
        "                                        cols[15]: averageRating,\n",
        "                                        cols[16]: maturityRating,\n",
        "                                        cols[17]: ratingsCount,\n",
        "                                        cols[18]: subtitle,\n",
        "                                        }, index=[0])\n",
        "                \n",
        "                frames = [df, book_data]\n",
        "                df = pd.concat(frames)\n",
        "                checkpoint = publisher\n",
        "\n",
        "        except Exception:\n",
        "          pass\n",
        "\n",
        "df = df.reset_index()\n",
        "df.head(100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.56 s, sys: 72.7 ms, total: 2.63 s\n",
            "Wall time: 42.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}